{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Estimation of Differential Equations\n",
    "\n",
    "Describe why differential equations are interesting, why they are used, and what you can get out of a Bayesian estimation (parameter estimation with quantified uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing, Distributions, DataFrames, DifferentialEquations\n",
    "\n",
    "# Import MCMCChain, Plots, and StatsPlots for visualizations and diagnostics.\n",
    "using MCMCChains, Plots, StatsPlots\n",
    "\n",
    "# Set a seed for reproducibility.\n",
    "using Random\n",
    "Random.seed!(12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lotka-Volterra Model\n",
    "\n",
    "Introduce Lotka-Volterra. Use some Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lotka_volterra(du,u,p,t)\n",
    "  x, y = u\n",
    "  α, β, δ, γ = p\n",
    "  du[1] = dx = (α - β*y)x\n",
    "  du[2] = dy = (δ*x - γ)y\n",
    "end\n",
    "p = [2.2, 1.0, 2.0, 0.4]\n",
    "u0 = [1.0,1.0]\n",
    "prob = ODEProblem(lotka_volterra,u0,(0.0,10.0),p)\n",
    "sol = solve(prob,Tsit5())\n",
    "plot(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe model.\n",
    "\n",
    "Now describe data generation process and saveat. Point to https://docs.sciml.ai/latest/basics/common_solver_opts/ since a new argument was introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odedata = Array(solve(prob,Tsit5(),saveat=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Lotka-Volterra with DiffEqBayes\n",
    "\n",
    "Start with the simple high level package. Point to https://github.com/SciML/DiffEqBayes.jl and the documentation on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqBayes\n",
    "t = 0:0.1:10.0\n",
    "priors = [Truncated(Normal(1.5,0.5),0.5,2.5),Truncated(Normal(1.2,0.5),0,2),Truncated(Normal(3.0,0.5),1,4),Truncated(Normal(1.0,0.5),0,2)]\n",
    "bayesian_result_turing = turing_inference(prob,Tsit5(),t,odedata,priors,num_samples=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate post fit analysis: how do you know the chains are good, and what the results saying? Are they correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Handling of Bayesian Estimation with Turing\n",
    "\n",
    "Now describe that we can directly use the differential equation solver inside of Turing to allow for more control. The same model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turing.setadbackend(:forwarddiff)\n",
    "\n",
    "@model function fitlv(data, ::Type{T}=Vector{Float64}) where {T}\n",
    "    σ ~ InverseGamma(2, 3)\n",
    "    α ~ Truncated(Normal(1.5,0.5),0.5,2.5)\n",
    "    β ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    γ ~ Truncated(Normal(3.0,0.5),1,4)\n",
    "    δ ~ Truncated(Normal(1.0,0.5),0,2)\n",
    "\n",
    "    p = [α,β,γ,δ]\n",
    "    prob = ODEProblem(lotka_volterra,u0,(0.0,10.0),p)\n",
    "    predicted = solve(prob,Tsit5(),saveat=0.1)\n",
    "\n",
    "    for i = 1:length(predicted)\n",
    "        data[:,i] ~ MvNormal(predicted[i], σ[1]*ones(length(predicted[i])))\n",
    "    end\n",
    "end\n",
    "\n",
    "model = fitlv(odedata)\n",
    "chain = sample(model, NUTS(.65),30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to Large Models: Adjoint Sensitivities\n",
    "\n",
    "Reference that DifferentialEquations.jl is very efficient for large stiff models. https://docs.sciml.ai/latest/tutorials/advanced_ode_example/ . https://github.com/SciML/DiffEqBenchmarks.jl\n",
    "\n",
    "Now introduce https://docs.sciml.ai/latest/analysis/sensitivity/ . Describe a bit about pervasive AD in Julia, and how `concrete_solve` plugs into those AD systems to allow for choosing advanced sensitivity analysis (derivative calculation) methods https://docs.sciml.ai/latest/analysis/sensitivity/#Sensitivity-Algorithms-1 . More details on these methods can be found at: https://docs.sciml.ai/latest/extras/sensitivity_math/.\n",
    "\n",
    "(Mention that `nothing` as the solver makes it use an automatic choice, which normally automatically detects stiffness so is safe in all cases, but this can also be `concrete_solve(prob,Tsit5(),saveat=0.1)` for example)\n",
    "\n",
    "While these sensitivity analysis methods may seem complicated (and they are!), using them is dead simple. Here is a version of the Lotka-Volterra model with adjoints enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ReverseDiff\n",
    "Turing.setadbackend(:reversediff)\n",
    "\n",
    "@model function fitlv(data, ::Type{T}=Vector{Float64}) where {T}\n",
    "    σ ~ InverseGamma(2, 3)\n",
    "    α ~ Truncated(Normal(1.5,0.5),0.5,2.5)\n",
    "    β ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    γ ~ Truncated(Normal(3.0,0.5),1,4)\n",
    "    δ ~ Truncated(Normal(1.0,0.5),0,2)\n",
    "\n",
    "    p = [α,β,γ,δ]\n",
    "    prob = ODEProblem(lotka_volterra,u0,(0.0,10.0),p)\n",
    "    predicted = concrete_solve(prob,nothing,saveat=0.1)\n",
    "\n",
    "    for i = 1:length(predicted)\n",
    "        data[:,i] ~ MvNormal(predicted[i], σ[1]*ones(length(predicted[i])))\n",
    "    end\n",
    "end;\n",
    "\n",
    "model = fitlv(odedata)\n",
    "chain = sample(model, NUTS(.65),30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we had to do is switch the AD backend to one of the adjoint-compatible backends (ReverseDiff, Tracker, or Zygote) and boom the system takes over and we're using adjoint methods! Notice that on this model adjoints are slower. This is because adjoints have a higher overhead on small parameter models and we suggest only using these methods for models with around 100 parameters or more. For more details, see https://arxiv.org/abs/1812.01892 .\n",
    "\n",
    "Now we can exercise control of the sensitivity analysis method that is used by using the `sensealg` keyword argument. Let's choose the `InterpolatingAdjoint` from https://docs.sciml.ai/latest/analysis/sensitivity/#Sensitivity-Algorithms-1 and enable a compiled ReverseDiff vector-Jacobian product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function fitlv(data, ::Type{T}=Vector{Float64}) where {T}\n",
    "    σ ~ InverseGamma(2, 3)\n",
    "    α ~ Truncated(Normal(1.5,0.5),0.5,2.5)\n",
    "    β ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    γ ~ Truncated(Normal(3.0,0.5),1,4)\n",
    "    δ ~ Truncated(Normal(1.0,0.5),0,2)\n",
    "\n",
    "    p = [α,β,γ,δ]\n",
    "    prob = ODEProblem(lotka_volterra,u0,(0.0,10.0),p)\n",
    "    predicted = concrete_solve(prob,nothing,saveat=0.1,\n",
    "                               sensealg=InterpolatingAdjoint(\n",
    "                                               autojacvec=ReverseDiffVJP(true)))\n",
    "\n",
    "    for i = 1:length(predicted)\n",
    "        data[:,i] ~ MvNormal(predicted[i], σ[1]*ones(length(predicted[i])))\n",
    "    end\n",
    "end;\n",
    "model = fitlv(odedata)\n",
    "chain = sample(model, NUTS(.65),30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples of adjoint usage on large parameter models, consult the [DiffEqFlux documentation](https://diffeqflux.sciml.ai/dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Process Noise: Estimation of Stochastic Differential Equations\n",
    "\n",
    "Describe the SDE model. Use some Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lotka_volterra_noise(du,u,p,t)\n",
    "    du[1] = p[5]*u[1]\n",
    "    du[2] = p[6]*u[2]\n",
    "end\n",
    "p = [1.5, 1.0, 3.0, 1.0, 0.3, 0.3]\n",
    "prob = SDEProblem(lotka_volterra,lotka_volterra_noise,u0,(0.0,10.0),p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve 3 times to show randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve(prob,saveat=0.01)\n",
    "plot(sol)\n",
    "sol = solve(prob,saveat=0.01)\n",
    "plot(sol)\n",
    "sol = solve(prob,saveat=0.01)\n",
    "plot(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now demonstrate plotting a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = solve(EnsembleProblem(prob),saveat=0.01,trajectories=1000)\n",
    "summ = MonteCarloSummary(sol)\n",
    "plot(summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from the means to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DiffEqBase.EnsembleAnalysis\n",
    "averagedata = Array(timeseries_steps_mean(sol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the means with Turing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turing.setadbackend(:forwarddiff)\n",
    "\n",
    "@model function fitlv(data, ::Type{T}=Vector{Float64}) where {T}\n",
    "    σ ~ InverseGamma(2, 3)\n",
    "    α ~ Truncated(Normal(1.5,0.5),0.5,2.5)\n",
    "    β ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    γ ~ Truncated(Normal(3.0,0.5),1,4)\n",
    "    δ ~ Truncated(Normal(1.0,0.5),0,2)\n",
    "    ϕ1 ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    ϕ2 ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "\n",
    "    p = [α,β,γ,δ,ϕ1,ϕ2]\n",
    "    prob = SDEProblem(lotka_volterra,lotka_volterra_noise,u0,(0.0,10.0),p)\n",
    "    ensemble_predicted = solve(EnsembleProblem(prob),saveat=0.01,trajectories=1000)\n",
    "    predicted_means = timeseries_steps_mean(ensemble_predicted)\n",
    "\n",
    "    for i = 1:length(predicted)\n",
    "        data[:,i] ~ MvNormal(predicted_means[i], σ[1]*ones(length(predicted_means[i])))\n",
    "    end\n",
    "end;\n",
    "\n",
    "model = fitlv(odedata)\n",
    "chain = sample(model, NUTS(.65),30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed Interaction Models: Estimation of Delay Differential Equations\n",
    "\n",
    "Explain the importance of delay differential equations. Show some Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function delay_lotka_volterra(du,u,h,p,t)\n",
    "  x, y = u\n",
    "  α,β,γ,δ = p\n",
    "  du[1] = α*h(p,t-1)[1] - β*x*y\n",
    "  du[2] = -γ*y + δ*x*y\n",
    "end\n",
    "p = (1.5,1.0,3.0,1.0); u0 = [1.0;1.0]\n",
    "tspan = (0.0,10.0)\n",
    "_h(p,t) = ones(2)\n",
    "prob1 = DDEProblem(delay_lotka_volterra,u0,_h,tspan,p)\n",
    "sol = solve(prob1)\n",
    "plot(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddedata = Array(solve(prob1,saveat=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turing.setadbackend(:forwarddiff)\n",
    "\n",
    "@model function fitlv(data, ::Type{T}=Vector{Float64}) where {T}\n",
    "    σ ~ InverseGamma(2, 3)\n",
    "    α ~ Truncated(Normal(1.5,0.5),0.5,2.5)\n",
    "    β ~ Truncated(Normal(1.2,0.5),0,2)\n",
    "    γ ~ Truncated(Normal(3.0,0.5),1,4)\n",
    "    δ ~ Truncated(Normal(1.0,0.5),0,2)\n",
    "\n",
    "    p = [α,β,γ,δ]\n",
    "    prob = DDEProblem(delay_lotka_volterra,u0,_h,tspan,p)\n",
    "    predicted = solve(prob,saveat=0.01)\n",
    "\n",
    "    for i = 1:length(predicted)\n",
    "        data[:,i] ~ MvNormal(predicted[i], σ[1]*ones(length(predicted[i])))\n",
    "    end\n",
    "end;\n",
    "\n",
    "model = fitlv(ddedata)\n",
    "chain = sample(model, NUTS(.65),30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
