<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Bayesian Neural Networks</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 70%;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>
</HEAD>

<BODY>
  <div class ="container">
    <div class = "row">
      <div class = "col-md-12 twelve columns">
        <div class="title">
          <h1 class="title">Bayesian Neural Networks</h1>
          
          
        </div>

        <p>In this tutorial, we demonstrate how one can implement a Bayesian Neural Network using a combination of Turing and <a href="https://github.com/FluxML/Flux.jl">Flux</a>, a suite of tools machine learning. We will use Flux to specify the neural network&#39;s layers and Turing to implement the probabalistic inference, with the goal of implementing a classification algorithm.</p>
<p>We will begin with importing the relevant libraries.</p>


<pre class='hljl'>
<span class='hljl-cs'># Import libraries.</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Turing</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Flux</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Plots</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Random</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ReverseDiff</span><span class='hljl-t'>

</span><span class='hljl-cs'># Hide sampling progress.</span><span class='hljl-t'>
</span><span class='hljl-n'>Turing</span><span class='hljl-oB'>.</span><span class='hljl-nf'>setprogress!</span><span class='hljl-p'>(</span><span class='hljl-kc'>false</span><span class='hljl-p'>);</span><span class='hljl-t'>

</span><span class='hljl-cs'># Use reverse_diff due to the number of parameters in neural networks.</span><span class='hljl-t'>
</span><span class='hljl-n'>Turing</span><span class='hljl-oB'>.</span><span class='hljl-nf'>setadbackend</span><span class='hljl-p'>(</span><span class='hljl-sc'>:reversediff</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
:reversediff
</pre>


<p>Our goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we&#39;ll be working with.</p>


<pre class='hljl'>
<span class='hljl-cs'># Number of points to generate.</span><span class='hljl-t'>
</span><span class='hljl-n'>N</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>80</span><span class='hljl-t'>
</span><span class='hljl-n'>M</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>round</span><span class='hljl-p'>(</span><span class='hljl-n'>Int</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-t'> </span><span class='hljl-oB'>/</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Random</span><span class='hljl-oB'>.</span><span class='hljl-nf'>seed!</span><span class='hljl-p'>(</span><span class='hljl-ni'>1234</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Generate artificial data.</span><span class='hljl-t'>
</span><span class='hljl-n'>x1s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> 
</span><span class='hljl-n'>xt1s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>([[</span><span class='hljl-n'>x1s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>M</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-n'>x1s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> 
</span><span class='hljl-nf'>append!</span><span class='hljl-p'>(</span><span class='hljl-n'>xt1s</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>([[</span><span class='hljl-n'>x1s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>M</span><span class='hljl-p'>]))</span><span class='hljl-t'>

</span><span class='hljl-n'>x1s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> 
</span><span class='hljl-n'>xt0s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>([[</span><span class='hljl-n'>x1s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>M</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-n'>x1s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>M</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nfB'>4.5</span><span class='hljl-p'>;</span><span class='hljl-t'> 
</span><span class='hljl-nf'>append!</span><span class='hljl-p'>(</span><span class='hljl-n'>xt0s</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>Array</span><span class='hljl-p'>([[</span><span class='hljl-n'>x1s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>x2s</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>M</span><span class='hljl-p'>]))</span><span class='hljl-t'>

</span><span class='hljl-cs'># Store all the data for later.</span><span class='hljl-t'>
</span><span class='hljl-n'>xs</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-n'>xt1s</span><span class='hljl-p'>;</span><span class='hljl-t'> </span><span class='hljl-n'>xt0s</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>ts</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>ones</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-oB'>*</span><span class='hljl-n'>M</span><span class='hljl-p'>);</span><span class='hljl-t'> </span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-oB'>*</span><span class='hljl-n'>M</span><span class='hljl-p'>)]</span><span class='hljl-t'>

</span><span class='hljl-cs'># Plot data points.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>
    </span><span class='hljl-n'>x1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>e</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-n'>e</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>xt1s</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>y1</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>e</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-n'>e</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>xt1s</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>x2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>e</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-n'>e</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>xt0s</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>y2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>e</span><span class='hljl-t'> </span><span class='hljl-oB'>-&gt;</span><span class='hljl-t'> </span><span class='hljl-n'>e</span><span class='hljl-p'>[</span><span class='hljl-ni'>2</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>xt0s</span><span class='hljl-p'>)</span><span class='hljl-t'>

    </span><span class='hljl-n'>Plots</span><span class='hljl-oB'>.</span><span class='hljl-nf'>scatter</span><span class='hljl-p'>(</span><span class='hljl-n'>x1</span><span class='hljl-p'>,</span><span class='hljl-n'>y1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;red&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>clim</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>0</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>Plots</span><span class='hljl-oB'>.</span><span class='hljl-nf'>scatter!</span><span class='hljl-p'>(</span><span class='hljl-n'>x2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>color</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;blue&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>clim</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>0</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span>
</pre>


<img src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="576" height="384" viewBox="0 0 2304 1536">
<defs>
  <clipPath id="clip220">
    <rect x="0" y="0" width="2304" height="1536"/>
  </clipPath>
</defs>
<path clip-path="url(#clip220)" d="
M0 1536 L2304 1536 L2304 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip221">
    <rect x="460" y="0" width="1614" height="1536"/>
  </clipPath>
</defs>
<path clip-path="url(#clip220)" d="
M143.208 1423.09 L2256.76 1423.09 L2256.76 47.2441 L143.208 47.2441  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip222">
    <rect x="143" y="47" width="2115" height="1377"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  382.358,1423.09 382.358,47.2441 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  794.51,1423.09 794.51,47.2441 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1206.66,1423.09 1206.66,47.2441 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1618.81,1423.09 1618.81,47.2441 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2030.97,1423.09 2030.97,47.2441 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,1423.09 2256.76,1423.09 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  382.358,1423.09 382.358,1406.58 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  794.51,1423.09 794.51,1406.58 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1206.66,1423.09 1206.66,1406.58 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1618.81,1423.09 1618.81,1406.58 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  2030.97,1423.09 2030.97,1406.58 
  "/>
<path clip-path="url(#clip220)" d="M 0 0 M353.77 1466.16 L383.446 1466.16 L383.446 1470.1 L353.77 1470.1 L353.77 1466.16 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M401.363 1452.51 L389.557 1470.95 L401.363 1470.95 L401.363 1452.51 M400.136 1448.43 L406.015 1448.43 L406.015 1470.95 L410.946 1470.95 L410.946 1474.84 L406.015 1474.84 L406.015 1482.99 L401.363 1482.99 L401.363 1474.84 L385.761 1474.84 L385.761 1470.33 L400.136 1448.43 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M766.964 1466.16 L796.64 1466.16 L796.64 1470.1 L766.964 1470.1 L766.964 1466.16 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M805.737 1479.06 L822.056 1479.06 L822.056 1482.99 L800.112 1482.99 L800.112 1479.06 Q802.774 1476.3 807.357 1471.67 Q811.964 1467.02 813.144 1465.68 Q815.39 1463.15 816.269 1461.42 Q817.172 1459.66 817.172 1457.97 Q817.172 1455.21 815.228 1453.48 Q813.306 1451.74 810.205 1451.74 Q808.006 1451.74 805.552 1452.51 Q803.121 1453.27 800.344 1454.82 L800.344 1450.1 Q803.168 1448.96 805.621 1448.39 Q808.075 1447.81 810.112 1447.81 Q815.482 1447.81 818.677 1450.49 Q821.871 1453.18 821.871 1457.67 Q821.871 1459.8 821.061 1461.72 Q820.274 1463.62 818.167 1466.21 Q817.589 1466.88 814.487 1470.1 Q811.385 1473.29 805.737 1479.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M1206.66 1451.51 Q1203.05 1451.51 1201.22 1455.08 Q1199.42 1458.62 1199.42 1465.75 Q1199.42 1472.85 1201.22 1476.42 Q1203.05 1479.96 1206.66 1479.96 Q1210.3 1479.96 1212.1 1476.42 Q1213.93 1472.85 1213.93 1465.75 Q1213.93 1458.62 1212.1 1455.08 Q1210.3 1451.51 1206.66 1451.51 M1206.66 1447.81 Q1212.47 1447.81 1215.53 1452.41 Q1218.61 1457 1218.61 1465.75 Q1218.61 1474.47 1215.53 1479.08 Q1212.47 1483.66 1206.66 1483.66 Q1200.85 1483.66 1197.77 1479.08 Q1194.72 1474.47 1194.72 1465.75 Q1194.72 1457 1197.77 1452.41 Q1200.85 1447.81 1206.66 1447.81 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M1613.47 1479.06 L1629.79 1479.06 L1629.79 1482.99 L1607.84 1482.99 L1607.84 1479.06 Q1610.5 1476.3 1615.09 1471.67 Q1619.69 1467.02 1620.87 1465.68 Q1623.12 1463.15 1624 1461.42 Q1624.9 1459.66 1624.9 1457.97 Q1624.9 1455.21 1622.96 1453.48 Q1621.04 1451.74 1617.94 1451.74 Q1615.74 1451.74 1613.28 1452.51 Q1610.85 1453.27 1608.07 1454.82 L1608.07 1450.1 Q1610.9 1448.96 1613.35 1448.39 Q1615.81 1447.81 1617.84 1447.81 Q1623.21 1447.81 1626.41 1450.49 Q1629.6 1453.18 1629.6 1457.67 Q1629.6 1459.8 1628.79 1461.72 Q1628 1463.62 1625.9 1466.21 Q1625.32 1466.88 1622.22 1470.1 Q1619.12 1473.29 1613.47 1479.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M2033.98 1452.51 L2022.17 1470.95 L2033.98 1470.95 L2033.98 1452.51 M2032.75 1448.43 L2038.63 1448.43 L2038.63 1470.95 L2043.56 1470.95 L2043.56 1474.84 L2038.63 1474.84 L2038.63 1482.99 L2033.98 1482.99 L2033.98 1474.84 L2018.37 1474.84 L2018.37 1470.33 L2032.75 1448.43 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  143.208,1261.09 2256.76,1261.09 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  143.208,999.213 2256.76,999.213 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  143.208,737.337 2256.76,737.337 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  143.208,475.461 2256.76,475.461 
  "/>
<polyline clip-path="url(#clip222)" style="stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  143.208,213.584 2256.76,213.584 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,1423.09 143.208,47.2441 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,1261.09 168.57,1261.09 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,999.213 168.57,999.213 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,737.337 168.57,737.337 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,475.461 168.57,475.461 
  "/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  143.208,213.584 168.57,213.584 
  "/>
<path clip-path="url(#clip220)" d="M 0 0 M51.4721 1261.54 L81.1479 1261.54 L81.1479 1265.48 L51.4721 1265.48 L51.4721 1261.54 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M99.0645 1247.88 L87.259 1266.33 L99.0645 1266.33 L99.0645 1247.88 M97.8376 1243.81 L103.717 1243.81 L103.717 1266.33 L108.648 1266.33 L108.648 1270.22 L103.717 1270.22 L103.717 1278.37 L99.0645 1278.37 L99.0645 1270.22 L83.4627 1270.22 L83.4627 1265.71 L97.8376 1243.81 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M53.5554 999.665 L83.2312 999.665 L83.2312 1003.6 L53.5554 1003.6 L53.5554 999.665 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M92.3284 1012.56 L108.648 1012.56 L108.648 1016.49 L86.7034 1016.49 L86.7034 1012.56 Q89.3654 1009.8 93.9488 1005.17 Q98.5552 1000.52 99.7358 999.179 Q101.981 996.656 102.861 994.92 Q103.764 993.16 103.764 991.47 Q103.764 988.716 101.819 986.98 Q99.8978 985.244 96.796 985.244 Q94.5969 985.244 92.1432 986.008 Q89.7127 986.771 86.9349 988.322 L86.9349 983.6 Q89.759 982.466 92.2126 981.887 Q94.6663 981.308 96.7034 981.308 Q102.074 981.308 105.268 983.994 Q108.463 986.679 108.463 991.17 Q108.463 993.299 107.652 995.22 Q106.865 997.119 104.759 999.711 Q104.18 1000.38 101.078 1003.6 Q97.9765 1006.79 92.3284 1012.56 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M96.7034 723.136 Q93.0923 723.136 91.2636 726.701 Q89.458 730.242 89.458 737.372 Q89.458 744.478 91.2636 748.043 Q93.0923 751.585 96.7034 751.585 Q100.338 751.585 102.143 748.043 Q103.972 744.478 103.972 737.372 Q103.972 730.242 102.143 726.701 Q100.338 723.136 96.7034 723.136 M96.7034 719.432 Q102.514 719.432 105.569 724.039 Q108.648 728.622 108.648 737.372 Q108.648 746.099 105.569 750.705 Q102.514 755.288 96.7034 755.288 Q90.8932 755.288 87.8145 750.705 Q84.759 746.099 84.759 737.372 Q84.759 728.622 87.8145 724.039 Q90.8932 719.432 96.7034 719.432 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M92.3284 488.805 L108.648 488.805 L108.648 492.741 L86.7034 492.741 L86.7034 488.805 Q89.3654 486.051 93.9488 481.421 Q98.5552 476.768 99.7358 475.426 Q101.981 472.903 102.861 471.167 Q103.764 469.407 103.764 467.718 Q103.764 464.963 101.819 463.227 Q99.8978 461.491 96.796 461.491 Q94.5969 461.491 92.1432 462.255 Q89.7127 463.019 86.9349 464.569 L86.9349 459.847 Q89.759 458.713 92.2126 458.134 Q94.6663 457.556 96.7034 457.556 Q102.074 457.556 105.268 460.241 Q108.463 462.926 108.463 467.417 Q108.463 469.546 107.652 471.468 Q106.865 473.366 104.759 475.958 Q104.18 476.63 101.078 479.847 Q97.9765 483.042 92.3284 488.805 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M99.0645 200.378 L87.259 218.827 L99.0645 218.827 L99.0645 200.378 M97.8376 196.304 L103.717 196.304 L103.717 218.827 L108.648 218.827 L108.648 222.716 L103.717 222.716 L103.717 230.864 L99.0645 230.864 L99.0645 222.716 L83.4627 222.716 L83.4627 218.202 L97.8376 196.304 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip222)" cx="1857.62" cy="111.813" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2020.78" cy="103.463" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1834.8" cy="114.596" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1736.36" cy="206.439" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2046.03" cy="188.022" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2101.79" cy="651.74" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1495.71" cy="616.16" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1586.62" cy="486.306" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1538.6" cy="596.56" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1847.26" cy="451.389" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1911.44" cy="123.234" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1319.81" cy="413.235" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1371.3" cy="526.411" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2196.94" cy="664.904" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1909.4" cy="644.738" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1414.01" cy="379.514" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1565.67" cy="240.557" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1914.02" cy="495.657" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1362.23" cy="407.2" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2091.18" cy="156.242" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="219.207" cy="1012.74" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="823.897" cy="1155.5" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="514.863" cy="1082.65" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="456.782" cy="1031.42" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="521.787" cy="1137.14" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="315.854" cy="1343.59" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="312.907" cy="1274.74" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="439.092" cy="1052.59" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="551.812" cy="1263.47" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="639.518" cy="1178.71" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="787.229" cy="1271.4" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="654.445" cy="842.294" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="418.054" cy="904.587" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="728.533" cy="1333.52" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="447.494" cy="1018.28" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="443.894" cy="1313.83" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="749.528" cy="935.267" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="792.278" cy="879.855" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="875.042" cy="1368.67" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="210.486" cy="926.301" r="14" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1709.56" cy="1220.52" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1437.36" cy="1031.05" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1873.6" cy="976.175" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1546.22" cy="1092.49" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1772.2" cy="1113.59" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1396.9" cy="1031.1" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1796.64" cy="1278.52" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1555.92" cy="890.559" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1411.8" cy="831.049" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2083.44" cy="923.572" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1897.1" cy="1116.23" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1623.02" cy="1335.95" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1414.48" cy="963.214" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2035.8" cy="813.116" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2086.85" cy="1140.41" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1391.18" cy="1116.31" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1668.18" cy="891.822" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1616.26" cy="1062.86" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="2003.39" cy="916.272" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1556" cy="1384.15" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="504.746" cy="178.994" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="299.525" cy="413.596" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="455.18" cy="265.319" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="356.657" cy="452.524" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="995.778" cy="498.128" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="239.155" cy="261.586" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="203.025" cy="476.037" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="699.867" cy="427.291" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="731.639" cy="316.199" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="457.875" cy="645.72" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="640.625" cy="132.329" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="556.463" cy="452.487" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="311.983" cy="605.267" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="776.345" cy="276.987" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="1102.28" cy="589.098" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="635.682" cy="623.949" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="783.036" cy="395.006" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="950.528" cy="86.1831" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="561.743" cy="462.21" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<circle clip-path="url(#clip222)" cx="345.76" cy="574.568" r="14" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.072"/>
<path clip-path="url(#clip220)" d="
M1900.45 274.546 L2186.3 274.546 L2186.3 93.1056 L1900.45 93.1056  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<polyline clip-path="url(#clip220)" style="stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none" points="
  1900.45,274.546 2186.3,274.546 2186.3,93.1056 1900.45,93.1056 1900.45,274.546 
  "/>
<circle clip-path="url(#clip220)" cx="1994.38" cy="153.586" r="23" fill="#ff0000" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="4.9152"/>
<path clip-path="url(#clip220)" d="M 0 0 M2102.16 173.273 Q2100.36 177.903 2098.64 179.315 Q2096.93 180.727 2094.06 180.727 L2090.66 180.727 L2090.66 177.162 L2093.16 177.162 Q2094.92 177.162 2095.89 176.328 Q2096.86 175.495 2098.04 172.393 L2098.8 170.449 L2088.32 144.94 L2092.83 144.94 L2100.93 165.217 L2109.04 144.94 L2113.55 144.94 L2102.16 173.273 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M2119.43 166.93 L2127.07 166.93 L2127.07 140.565 L2118.76 142.231 L2118.76 137.972 L2127.02 136.306 L2131.7 136.306 L2131.7 166.93 L2139.34 166.93 L2139.34 170.866 L2119.43 170.866 L2119.43 166.93 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip220)" cx="1994.38" cy="214.066" r="23" fill="#0000ff" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="4.9152"/>
<path clip-path="url(#clip220)" d="M 0 0 M2102.16 233.753 Q2100.36 238.383 2098.64 239.795 Q2096.93 241.207 2094.06 241.207 L2090.66 241.207 L2090.66 237.642 L2093.16 237.642 Q2094.92 237.642 2095.89 236.808 Q2096.86 235.975 2098.04 232.873 L2098.8 230.929 L2088.32 205.42 L2092.83 205.42 L2100.93 225.697 L2109.04 205.42 L2113.55 205.42 L2102.16 233.753 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip220)" d="M 0 0 M2122.65 227.41 L2138.97 227.41 L2138.97 231.346 L2117.02 231.346 L2117.02 227.41 Q2119.68 224.656 2124.27 220.026 Q2128.87 215.373 2130.05 214.031 Q2132.3 211.508 2133.18 209.772 Q2134.08 208.012 2134.08 206.323 Q2134.08 203.568 2132.14 201.832 Q2130.22 200.096 2127.11 200.096 Q2124.92 200.096 2122.46 200.86 Q2120.03 201.623 2117.25 203.174 L2117.25 198.452 Q2120.08 197.318 2122.53 196.739 Q2124.98 196.161 2127.02 196.161 Q2132.39 196.161 2135.59 198.846 Q2138.78 201.531 2138.78 206.022 Q2138.78 208.151 2137.97 210.073 Q2137.18 211.971 2135.08 214.563 Q2134.5 215.235 2131.4 218.452 Q2128.29 221.647 2122.65 227.41 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /></svg>
"  />

<h2>Building a Neural Network</h2>
<p>The next step is to define a <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward neural network</a> where we express our parameters as distribtuions, and not single points as with traditional neural networks. The two functions below, <code>unpack</code> and <code>nn_forward</code> are helper functions we need when we specify our model in Turing.</p>
<p><code>unpack</code> takes a vector of parameters and partitions them between weights and biases. <code>nn_forward</code> constructs a neural network with the variables generated in <code>unpack</code> and returns a prediction based on the weights provided.</p>
<p>The <code>unpack</code> and <code>nn_forward</code> functions are explicity designed to create a neural network with two hidden layers and one output layer, as shown below.</p>
<p>&lt;img width&#61;&quot;320&quot; alt&#61;&quot;nn-diagram&quot; src&#61;&quot;https://user-images.githubusercontent.com/422990/47970321-bd172080-e038-11e8-9c6d-6c2bd790bd8a.png&quot;&gt;</p>
<p>The end of this tutorial provides some code that can be used to generate more general network shapes.</p>


<pre class='hljl'>
<span class='hljl-cs'># Turn a vector into a set of weights and biases.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>unpack</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>W₁</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>6</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>);</span><span class='hljl-t'>   
    </span><span class='hljl-n'>b₁</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>7</span><span class='hljl-oB'>:</span><span class='hljl-ni'>9</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>)</span><span class='hljl-t'>
    
    </span><span class='hljl-n'>W₂</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>10</span><span class='hljl-oB'>:</span><span class='hljl-ni'>15</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>3</span><span class='hljl-p'>);</span><span class='hljl-t'> 
    </span><span class='hljl-n'>b₂</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>16</span><span class='hljl-oB'>:</span><span class='hljl-ni'>17</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>
    
    </span><span class='hljl-n'>Wₒ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>18</span><span class='hljl-oB'>:</span><span class='hljl-ni'>19</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>2</span><span class='hljl-p'>);</span><span class='hljl-t'> 
    </span><span class='hljl-n'>bₒ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>[</span><span class='hljl-ni'>20</span><span class='hljl-oB'>:</span><span class='hljl-ni'>20</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>)</span><span class='hljl-t'>   
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>W₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>W₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Wₒ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>bₒ</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-cs'># Construct a neural network using Flux and return a predicted value.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>nn_params</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>W₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>W₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Wₒ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>bₒ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>unpack</span><span class='hljl-p'>(</span><span class='hljl-n'>nn_params</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>nn</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chain</span><span class='hljl-p'>(</span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-n'>W₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₁</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>tanh</span><span class='hljl-p'>),</span><span class='hljl-t'>
               </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-n'>W₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>b₂</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>tanh</span><span class='hljl-p'>),</span><span class='hljl-t'>
               </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-n'>Wₒ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>bₒ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>σ</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>nn</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>The probabalistic model specification below creates a <code>params</code> variable, which has 20 normally distributed variables. Each entry in the <code>params</code> vector represents weights and biases of our neural net.</p>


<pre class='hljl'>
<span class='hljl-cs'># Create a regularization term and a Gaussain prior variance term.</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.09</span><span class='hljl-t'>
</span><span class='hljl-n'>sig</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sqrt</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-t'> </span><span class='hljl-oB'>/</span><span class='hljl-t'> </span><span class='hljl-n'>alpha</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-cs'># Specify the probabalistic model.</span><span class='hljl-t'>
</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>bayes_nn</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ts</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-cs'># Create the weight and bias vector.</span><span class='hljl-t'>
    </span><span class='hljl-n'>nn_params</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-ni'>20</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>sig</span><span class='hljl-t'> </span><span class='hljl-oB'>.*</span><span class='hljl-t'> </span><span class='hljl-nf'>ones</span><span class='hljl-p'>(</span><span class='hljl-ni'>20</span><span class='hljl-p'>))</span><span class='hljl-t'>
    
    </span><span class='hljl-cs'># Calculate predictions for the inputs given the weights</span><span class='hljl-t'>
    </span><span class='hljl-cs'># and biases in theta.</span><span class='hljl-t'>
    </span><span class='hljl-n'>preds</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>nn_params</span><span class='hljl-p'>)</span><span class='hljl-t'>
    
    </span><span class='hljl-cs'># Observe each prediction.</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>ts</span><span class='hljl-p'>)</span><span class='hljl-t'>
        </span><span class='hljl-n'>ts</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Bernoulli</span><span class='hljl-p'>(</span><span class='hljl-n'>preds</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>])</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>Inference can now be performed by calling <code>sample</code>. We use the <code>HMC</code> sampler here.</p>


<pre class='hljl'>
<span class='hljl-cs'># Perform inference.</span><span class='hljl-t'>
</span><span class='hljl-n'>N</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>5000</span><span class='hljl-t'>
</span><span class='hljl-n'>ch</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-nf'>bayes_nn</span><span class='hljl-p'>(</span><span class='hljl-nf'>hcat</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-oB'>...</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>ts</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>HMC</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.05</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>4</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>N</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: DimensionMismatch&#40;&quot;expected bias of size &#40;2,&#41;, got size &#40;2, 1&#41;&quot;&#41;
</pre>


<p>Now we extract the weights and biases from the sampled chain. We&#39;ll use these primarily in determining how good a classifier our model is.</p>


<pre class='hljl'>
<span class='hljl-cs'># Extract all weight and bias parameters.</span><span class='hljl-t'>
</span><span class='hljl-n'>theta</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>MCMCChains</span><span class='hljl-oB'>.</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>ch</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:nn_params</span><span class='hljl-p'>)</span><span class='hljl-oB'>.</span><span class='hljl-n'>value</span><span class='hljl-p'>;</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: ch not defined
</pre>


<h2>Prediction Visualization</h2>
<p>We can use <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">MAP estimation</a> to classify our population by using the set of weights that provided the highest log posterior.</p>


<pre class='hljl'>
<span class='hljl-cs'># Plot the data we have.</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>

</span><span class='hljl-cs'># Find the index that provided the highest log posterior in the chain.</span><span class='hljl-t'>
</span><span class='hljl-n'>_</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>findmax</span><span class='hljl-p'>(</span><span class='hljl-n'>ch</span><span class='hljl-p'>[</span><span class='hljl-sc'>:lp</span><span class='hljl-p'>])</span><span class='hljl-t'>

</span><span class='hljl-cs'># Extract the max row value from i.</span><span class='hljl-t'>
</span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-oB'>.</span><span class='hljl-n'>I</span><span class='hljl-p'>[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'>

</span><span class='hljl-cs'># Plot the posterior distribution with a contour plot.</span><span class='hljl-t'>
</span><span class='hljl-n'>x_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>y_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>([</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>:</span><span class='hljl-p'>])[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-n'>y_range</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>contour!</span><span class='hljl-p'>(</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Z</span><span class='hljl-p'>)</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: ch not defined
</pre>


<p>The contour plot above shows that the MAP method is not too bad at classifying our data.</p>
<p>Now we can visualize our predictions.</p>
:&#36;
<p>p&#40;\tilde&#123;x&#125; | X, \alpha&#41; &#61; \int<em>&#123;\theta&#125; p&#40;\tilde&#123;x&#125; | \theta&#41; p&#40;\theta | X, \alpha&#41; \approx \sum</em>&#123;\theta \sim p&#40;\theta | X, \alpha&#41;&#125;f_&#123;\theta&#125;&#40;\tilde&#123;x&#125;&#41;  &#36;</p>
<p>The <code>nn_predict</code> function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain.</p>


<pre class='hljl'>
<span class='hljl-cs'># Return the average predicted value across</span><span class='hljl-t'>
</span><span class='hljl-cs'># multiple weights.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_predict</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>num</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-nf'>mean</span><span class='hljl-p'>([</span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-oB'>:</span><span class='hljl-p'>])[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>10</span><span class='hljl-oB'>:</span><span class='hljl-n'>num</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span>
</pre>



<p>Next, we use the <code>nn_predict</code> function to predict the value at a sample of points where the <code>x</code> and <code>y</code> coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data.</p>


<pre class='hljl'>
<span class='hljl-cs'># Plot the average prediction.</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>

</span><span class='hljl-n'>n_end</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1500</span><span class='hljl-t'>
</span><span class='hljl-n'>x_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>y_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>nn_predict</span><span class='hljl-p'>([</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_end</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-n'>y_range</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>contour!</span><span class='hljl-p'>(</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Z</span><span class='hljl-p'>)</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: theta not defined
</pre>


<p>If you are interested in how the predictive power of our Bayesian neural network evolved between samples, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000. </p>


<pre class='hljl'>
<span class='hljl-cs'># Number of iterations to plot.</span><span class='hljl-t'>
</span><span class='hljl-n'>n_end</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>500</span><span class='hljl-t'>

</span><span class='hljl-n'>anim</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@gif</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-oB'>=</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>n_end</span><span class='hljl-t'>
    </span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>
    </span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>([</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-oB'>:</span><span class='hljl-p'>])[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-n'>y_range</span><span class='hljl-p'>]</span><span class='hljl-t'>
    </span><span class='hljl-nf'>contour!</span><span class='hljl-p'>(</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Z</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>title</span><span class='hljl-oB'>=</span><span class='hljl-s'>&quot;Iteration </span><span class='hljl-si'>$i</span><span class='hljl-s'>&quot;</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>clim</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>0</span><span class='hljl-p'>,</span><span class='hljl-ni'>1</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'> </span><span class='hljl-n'>every</span><span class='hljl-t'> </span><span class='hljl-ni'>5</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: theta not defined
</pre>


<h2>Variational Inference &#40;ADVI&#41;</h2>
<p>We can also use Turing&#39;s variational inference tools to estimate the parameters of this model. See <a href="https://turing.ml/dev/docs/for-developers/variational_inference">variational inference</a> for more information.</p>


<pre class='hljl'>
<span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Bijectors</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>Turing</span><span class='hljl-oB'>:</span><span class='hljl-t'> </span><span class='hljl-n'>Variational</span><span class='hljl-t'>
</span><span class='hljl-k'>using</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedVI</span><span class='hljl-t'>

</span><span class='hljl-n'>m</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>bayes_nn</span><span class='hljl-p'>(</span><span class='hljl-nf'>hcat</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-oB'>...</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>ts</span><span class='hljl-p'>);</span><span class='hljl-t'>

</span><span class='hljl-n'>q</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>Variational</span><span class='hljl-oB'>.</span><span class='hljl-nf'>meanfield</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>)</span><span class='hljl-t'>

</span><span class='hljl-n'>μ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>randn</span><span class='hljl-p'>(</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>q</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>ω</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-ni'>1</span><span class='hljl-t'> </span><span class='hljl-oB'>.*</span><span class='hljl-t'> </span><span class='hljl-nf'>ones</span><span class='hljl-p'>(</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>q</span><span class='hljl-p'>))</span><span class='hljl-t'>

</span><span class='hljl-n'>q</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>AdvancedVI</span><span class='hljl-oB'>.</span><span class='hljl-nf'>update</span><span class='hljl-p'>(</span><span class='hljl-n'>q</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>μ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>exp</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>ω</span><span class='hljl-p'>));</span><span class='hljl-t'>

</span><span class='hljl-n'>advi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>ADVI</span><span class='hljl-p'>(</span><span class='hljl-ni'>10</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>5_000</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>q_hat</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>vi</span><span class='hljl-p'>(</span><span class='hljl-n'>m</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>advi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>q</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: DimensionMismatch&#40;&quot;expected bias of size &#40;2,&#41;, got size &#40;2, 1&#41;&quot;&#41;
</pre>



<pre class='hljl'>
<span class='hljl-n'>samples</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>transpose</span><span class='hljl-p'>(</span><span class='hljl-nf'>rand</span><span class='hljl-p'>(</span><span class='hljl-n'>q_hat</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>5000</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>ch_vi</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chains</span><span class='hljl-p'>(</span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>samples</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>size</span><span class='hljl-p'>(</span><span class='hljl-n'>samples</span><span class='hljl-p'>)</span><span class='hljl-oB'>...</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>string</span><span class='hljl-oB'>.</span><span class='hljl-p'>(</span><span class='hljl-n'>MCMCChains</span><span class='hljl-oB'>.</span><span class='hljl-nf'>namesingroup</span><span class='hljl-p'>(</span><span class='hljl-n'>ch</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:nn_params</span><span class='hljl-p'>)));</span><span class='hljl-t'>

</span><span class='hljl-cs'># Extract all weight and bias parameters.</span><span class='hljl-t'>
</span><span class='hljl-n'>theta</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>MCMCChains</span><span class='hljl-oB'>.</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>ch_vi</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:nn_params</span><span class='hljl-p'>)</span><span class='hljl-oB'>.</span><span class='hljl-n'>value</span><span class='hljl-p'>;</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: q_hat not defined
</pre>



<pre class='hljl'>
<span class='hljl-cs'># Plot the average prediction.</span><span class='hljl-t'>
</span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>

</span><span class='hljl-n'>n_end</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1500</span><span class='hljl-t'>
</span><span class='hljl-n'>x_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>y_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>nn_predict</span><span class='hljl-p'>([</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>n_end</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-n'>y_range</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>contour!</span><span class='hljl-p'>(</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Z</span><span class='hljl-p'>)</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: theta not defined
</pre>


<h2>Generic Bayesian Neural Networks</h2>
<p>The below code is intended for use in more general applications, where you need to be able to change the basic network shape fluidly. The code above is highly rigid, and adapting it for other architectures would be time consuming. Currently the code below only supports networks of <code>Dense</code> layers.</p>
<p>Here, we solve the same problem as above, but with three additional 2x2 <code>tanh</code> hidden layers. You can modify the <code>network_shape</code> variable to specify differing architectures. A tuple <code>&#40;3,2, :tanh&#41;</code> means you want to construct a <code>Dense</code> layer with 3 outputs, 2 inputs, and a <code>tanh</code> activation function. You can provide any activation function found in Flux by entering it as a <code>Symbol</code> &#40;e.g., the <code>tanh</code> function is entered in the third part of the tuple as <code>:tanh</code>&#41;.</p>


<pre class='hljl'>
<span class='hljl-cs'># Specify the network architecture.</span><span class='hljl-t'>
</span><span class='hljl-n'>network_shape</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-t'>
    </span><span class='hljl-p'>(</span><span class='hljl-ni'>3</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:tanh</span><span class='hljl-p'>),</span><span class='hljl-t'>
    </span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-ni'>3</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:tanh</span><span class='hljl-p'>),</span><span class='hljl-t'> 
    </span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-p'>,</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:σ</span><span class='hljl-p'>)]</span><span class='hljl-t'>

</span><span class='hljl-cs'># Regularization, parameter variance, and total number of</span><span class='hljl-t'>
</span><span class='hljl-cs'># parameters.</span><span class='hljl-t'>
</span><span class='hljl-n'>alpha</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.09</span><span class='hljl-t'>
</span><span class='hljl-n'>sig</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sqrt</span><span class='hljl-p'>(</span><span class='hljl-nfB'>1.0</span><span class='hljl-t'> </span><span class='hljl-oB'>/</span><span class='hljl-t'> </span><span class='hljl-n'>alpha</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>num_params</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sum</span><span class='hljl-p'>([</span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>o</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>o</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>_</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>])</span><span class='hljl-t'>

</span><span class='hljl-cs'># This modification of the unpack function generates a series of vectors</span><span class='hljl-t'>
</span><span class='hljl-cs'># given a network shape.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>unpack</span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>index</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'>
    </span><span class='hljl-n'>weights</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[]</span><span class='hljl-t'>
    </span><span class='hljl-n'>biases</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[]</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>layer</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-t'>
        </span><span class='hljl-n'>rows</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cols</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>_</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>layer</span><span class='hljl-t'>
        </span><span class='hljl-n'>size</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>rows</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>cols</span><span class='hljl-t'>
        </span><span class='hljl-n'>last_index_w</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>size</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>index</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'>
        </span><span class='hljl-n'>last_index_b</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>last_index_w</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>rows</span><span class='hljl-t'>
        </span><span class='hljl-nf'>push!</span><span class='hljl-p'>(</span><span class='hljl-n'>weights</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-p'>[</span><span class='hljl-n'>index</span><span class='hljl-oB'>:</span><span class='hljl-n'>last_index_w</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>rows</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>cols</span><span class='hljl-p'>))</span><span class='hljl-t'>
        </span><span class='hljl-nf'>push!</span><span class='hljl-p'>(</span><span class='hljl-n'>biases</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>reshape</span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-p'>[</span><span class='hljl-n'>last_index_w</span><span class='hljl-oB'>+</span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-n'>last_index_b</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>rows</span><span class='hljl-p'>))</span><span class='hljl-t'>
        </span><span class='hljl-n'>index</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>last_index_b</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-n'>weights</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>biases</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-cs'># Generate an abstract neural network given a shape, </span><span class='hljl-t'>
</span><span class='hljl-cs'># and return a prediction.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>θ</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-oB'>::</span><span class='hljl-n'>AbstractVector</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>weights</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>biases</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>unpack</span><span class='hljl-p'>(</span><span class='hljl-n'>θ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-n'>layers</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[]</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-nf'>eachindex</span><span class='hljl-p'>(</span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)</span><span class='hljl-t'>
        </span><span class='hljl-nf'>push!</span><span class='hljl-p'>(</span><span class='hljl-n'>layers</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>Dense</span><span class='hljl-p'>(</span><span class='hljl-n'>weights</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>],</span><span class='hljl-t'>
            </span><span class='hljl-n'>biases</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>],</span><span class='hljl-t'>
            </span><span class='hljl-nf'>eval</span><span class='hljl-p'>(</span><span class='hljl-n'>network_shape</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>][</span><span class='hljl-ni'>3</span><span class='hljl-p'>])))</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
    </span><span class='hljl-n'>nn</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Chain</span><span class='hljl-p'>(</span><span class='hljl-n'>layers</span><span class='hljl-oB'>...</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>return</span><span class='hljl-t'> </span><span class='hljl-nf'>nn</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-cs'># General Turing specification for a BNN model.</span><span class='hljl-t'>
</span><span class='hljl-nd'>@model</span><span class='hljl-t'> </span><span class='hljl-nf'>bayes_nn_general</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ts</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>num_params</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-k'>begin</span><span class='hljl-t'>
    </span><span class='hljl-n'>θ</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>MvNormal</span><span class='hljl-p'>(</span><span class='hljl-nf'>zeros</span><span class='hljl-p'>(</span><span class='hljl-n'>num_params</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>sig</span><span class='hljl-t'> </span><span class='hljl-oB'>.*</span><span class='hljl-t'> </span><span class='hljl-nf'>ones</span><span class='hljl-p'>(</span><span class='hljl-n'>num_params</span><span class='hljl-p'>))</span><span class='hljl-t'>
    </span><span class='hljl-n'>preds</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>θ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>ts</span><span class='hljl-p'>)</span><span class='hljl-t'>
        </span><span class='hljl-n'>ts</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-nf'>Bernoulli</span><span class='hljl-p'>(</span><span class='hljl-n'>preds</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>])</span><span class='hljl-t'>
    </span><span class='hljl-k'>end</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-t'>

</span><span class='hljl-cs'># Perform inference.</span><span class='hljl-t'>
</span><span class='hljl-n'>num_samples</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-ni'>500</span><span class='hljl-t'>
</span><span class='hljl-n'>ch2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>sample</span><span class='hljl-p'>(</span><span class='hljl-nf'>bayes_nn_general</span><span class='hljl-p'>(</span><span class='hljl-nf'>hcat</span><span class='hljl-p'>(</span><span class='hljl-n'>xs</span><span class='hljl-oB'>...</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>ts</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>num_params</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-nf'>NUTS</span><span class='hljl-p'>(</span><span class='hljl-nfB'>0.65</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>num_samples</span><span class='hljl-p'>);</span>
</pre>


<pre class="julia-error">
ERROR: MethodError: ReverseDiff.TrackedReal&#123;Float64, Float64, ReverseDiff.TrackedArray&#123;Float64, Float64, 2, Matrix&#123;Float64&#125;, Matrix&#123;Float64&#125;&#125;&#125;&#40;::ForwardDiff.Dual&#123;ForwardDiff.Tag&#123;ReverseDiff.var&quot;#105#107&quot;&#123;DataType, Tuple&#123;&#125;, Val&#123;&#40;1,&#41;&#125;&#125;, Float64&#125;, Float64, 1&#125;&#41; is ambiguous. Candidates:
  &#40;T::Type&#123;var&quot;#s31&quot;&#125; where var&quot;#s31&quot;&lt;:Real&#41;&#40;x::ForwardDiff.Dual&#41; in Tracker at /home/cameron/.julia/packages/Tracker/YNNTM/src/lib/real.jl:111
  ReverseDiff.TrackedReal&#123;V, D, O&#125;&#40;value&#41; where &#123;V, D, O&#125; in ReverseDiff at /home/cameron/.julia/packages/ReverseDiff/iHmB4/src/tracked.jl:56
Possible fix, define
  ReverseDiff.TrackedReal&#123;V, D, O&#125;&#40;::ForwardDiff.Dual&#41; where &#123;V, D, O&#125;
</pre>



<pre class='hljl'>
<span class='hljl-cs'># This function makes predictions based on network shape.</span><span class='hljl-t'>
</span><span class='hljl-k'>function</span><span class='hljl-t'> </span><span class='hljl-nf'>nn_predict</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>num</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)</span><span class='hljl-t'>
    </span><span class='hljl-nf'>mean</span><span class='hljl-p'>([</span><span class='hljl-nf'>nn_forward</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>theta</span><span class='hljl-p'>[</span><span class='hljl-n'>i</span><span class='hljl-p'>,</span><span class='hljl-oB'>:</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>i</span><span class='hljl-t'> </span><span class='hljl-kp'>in</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-oB'>:</span><span class='hljl-ni'>10</span><span class='hljl-oB'>:</span><span class='hljl-n'>num</span><span class='hljl-p'>])</span><span class='hljl-t'>
</span><span class='hljl-k'>end</span><span class='hljl-p'>;</span><span class='hljl-t'>

</span><span class='hljl-cs'># Extract the θ parameters from the sampled chain.</span><span class='hljl-t'>
</span><span class='hljl-n'>params2</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>MCMCChains</span><span class='hljl-oB'>.</span><span class='hljl-nf'>group</span><span class='hljl-p'>(</span><span class='hljl-n'>ch2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-sc'>:θ</span><span class='hljl-p'>)</span><span class='hljl-oB'>.</span><span class='hljl-n'>value</span><span class='hljl-t'>

</span><span class='hljl-nf'>plot_data</span><span class='hljl-p'>()</span><span class='hljl-t'>

</span><span class='hljl-n'>x_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>y_range</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>collect</span><span class='hljl-p'>(</span><span class='hljl-nf'>range</span><span class='hljl-p'>(</span><span class='hljl-oB'>-</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>stop</span><span class='hljl-oB'>=</span><span class='hljl-ni'>6</span><span class='hljl-p'>,</span><span class='hljl-n'>length</span><span class='hljl-oB'>=</span><span class='hljl-ni'>25</span><span class='hljl-p'>))</span><span class='hljl-t'>
</span><span class='hljl-n'>Z</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nf'>nn_predict</span><span class='hljl-p'>([</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-p'>],</span><span class='hljl-t'> </span><span class='hljl-n'>params2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>ch2</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>network_shape</span><span class='hljl-p'>)[</span><span class='hljl-ni'>1</span><span class='hljl-p'>]</span><span class='hljl-t'> </span><span class='hljl-k'>for</span><span class='hljl-t'> </span><span class='hljl-n'>x</span><span class='hljl-oB'>=</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-oB'>=</span><span class='hljl-n'>y_range</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-nf'>contour!</span><span class='hljl-p'>(</span><span class='hljl-n'>x_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y_range</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Z</span><span class='hljl-p'>)</span>
</pre>


<pre class="julia-error">
ERROR: UndefVarError: ch2 not defined
</pre>


<p>This has been an introduction to the applications of Turing and Flux in defining Bayesian neural networks.</p>


<div class="markdown"><h2>Appendix</h2>
<p>This tutorial is part of the TuringTutorials repository, found at: <a href="https://github.com/TuringLang/TuringTutorials">https://github.com/TuringLang/TuringTutorials</a>.</p>
</div>
<div class="markdown"><p>To locally run this tutorial, do the following commands:</p>
<pre><code class="language-julia, eval &#61; false">using TuringTutorials
TuringTutorials.weave_file&#40;&quot;03-bayesian-neural-network&quot;, &quot;03_bayesian-neural-network.jmd&quot;&#41;</code></pre>
</div>
<div class="markdown"><p>Computer Information:</p>
</div>
<div class="markdown"><pre><code>Julia Version 1.6.0
Commit f9720dc2eb &#40;2021-03-24 12:55 UTC&#41;
Platform Info:
  OS: Linux &#40;x86_64-pc-linux-gnu&#41;
  CPU: Intel&#40;R&#41; Core&#40;TM&#41; i9-9900K CPU @ 3.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-11.0.1 &#40;ORCJIT, skylake&#41;
Environment:
  JULIA_CMDSTAN_HOME &#61; /home/cameron/stan/
  JULIA_NUM_THREADS &#61; 16
</code></pre>
</div>
<div class="markdown"><p>Package Information:</p>
</div>
<div class="markdown"><pre><code>      Status &#96;~/.julia/dev/TuringTutorials/tutorials/03-bayesian-neural-network/Project.toml&#96;
  &#91;b5ca4192&#93; AdvancedVI v0.1.1
  &#91;76274a88&#93; Bijectors v0.8.13
  &#91;587475ba&#93; Flux v0.12.0
  &#91;91a5bcdd&#93; Plots v1.11.1
  &#91;37e2e3b7&#93; ReverseDiff v1.7.0
  &#91;fce5fe82&#93; Turing v0.15.1
  &#91;9a3f8284&#93; Random
</code></pre>
</div>


        <HR/>
        <div class="footer">
          <p>
            Published from <a href="03_bayesian-neural-network.jmd">03_bayesian-neural-network.jmd</a>
            using <a href="http://github.com/JunoLab/Weave.jl">Weave.jl</a> v0.10.7 on 2021-04-05.
          </p>
        </div>
      </div>
    </div>
  </div>
</BODY>

</HTML>
